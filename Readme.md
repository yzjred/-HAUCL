
### Requirements

- Python 3.10.13
- pytorch 2.1.2
- CUDA 11.8
- pyg 2.4.0

### Dataset
The raw data can be found at [IEMOCAP](https://sail.usc.edu/iemocap/ "IEMOCAP") and [MELD](https://github.com/SenticNet/MELD "MELD").

We use pre-extracted featuresï¼Œplease refer [M3NET](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Multivariate_Multi-Frequency_and_Multimodal_Rethinking_Graph_Neural_Networks_for_Emotion_CVPR_2023_paper.html)

### Training examples

To train on IEMOCAP: run iemocap.py

To train on MELD: run train.py

